{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport copy\nimport matplotlib.pyplot as plt\nimport math\nimport os\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:12:53.383572Z","iopub.execute_input":"2022-06-27T15:12:53.384294Z","iopub.status.idle":"2022-06-27T15:12:55.413735Z","shell.execute_reply.started":"2022-06-27T15:12:53.384204Z","shell.execute_reply":"2022-06-27T15:12:55.412852Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Changes made in the custom Dataset class for Flowers102 in Pytorch to address the different split that was requested","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import Any, Tuple, Callable, Optional\n\nimport PIL.Image\n\nfrom torchvision.datasets.utils import check_integrity, download_and_extract_archive, download_url, verify_str_arg\nfrom torchvision.datasets.vision import VisionDataset\n\nfrom sklearn.model_selection import train_test_split\n\n\nclass Flowers102(VisionDataset):\n    \"\"\"`Oxford 102 Flower <https://www.robots.ox.ac.uk/~vgg/data/flowers/102/>`_ Dataset.\n    Oxford 102 Flower is an image classification dataset consisting of 102 flower categories. The\n    flowers were chosen to be flowers commonly occurring in the United Kingdom. Each class consists of\n    between 40 and 258 images.\n\n    The images have large scale, pose and light variations. In addition, there are categories that\n    have large variations within the category, and several very similar categories.\n\n    Args:\n        root (string): Root directory of the dataset.\n        split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"val\"``, or ``\"test\"``.\n        transform (callable, optional): A function/transform that takes in an PIL image and returns a\n            transformed version. E.g, ``transforms.RandomCrop``.\n        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n    \"\"\"\n\n    _download_url_prefix = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/\"\n    _file_dict = {  # filename, md5\n        \"image\": (\"102flowers.tgz\", \"52808999861908f626f3c1f4e79d11fa\"),\n        \"label\": (\"imagelabels.mat\", \"e0620be6f572b9609742df49c70aed4d\"),\n        \"setid\": (\"setid.mat\", \"a5357ecc9cb78c4bef273ce3793fc85c\"),\n    }\n    _splits_map = {\"train\": \"trnid\", \"val\": \"valid\", \"test\": \"tstid\"}\n\n    def __init__(\n        self,\n        root: str,\n        split: str = \"train\",\n        transform: Optional[Callable] = None,\n        target_transform: Optional[Callable] = None,\n        download: bool = False,\n        random_s: int = 123\n    ) -> None:\n        super().__init__(root, transform=transform, target_transform=target_transform)\n        self._split = verify_str_arg(split, \"split\", (\"train\", \"val\", \"test\"))\n        self._base_folder = Path(self.root) / \"flowers-102\"\n        self._images_folder = self._base_folder / \"jpg\"\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n\n        from scipy.io import loadmat\n        labels = loadmat(self._base_folder / self._file_dict[\"label\"][0], squeeze_me=True)\n        image_id_to_label = dict(enumerate(labels[\"labels\"].tolist(), 1))\n        \n        # convert dict to DF\n        img_to_label = pd.DataFrame(image_id_to_label, index=[0]).T\n        img_to_label[\"label\"] = img_to_label[0]\n        img_to_label[\"index\"] = img_to_label.index\n        del img_to_label[0]\n        \n        # splitting the data - using ramdom state for fixed split\n        X_train, X_temp, y_train, y_temp = train_test_split(img_to_label[[\"index\"]],img_to_label[\"label\"],test_size=0.5,random_state=random_s)\n        X_val, X_test, y_val, y_test = train_test_split(X_temp,y_temp,test_size=0.5,random_state=random_s+1)\n\n        # extract images file names & labels according to requested data set - train\\validation\\test\n        image_ids, labels = (X_train, y_train) if self._split == 'train' else ((X_val, y_val) if self._split == 'val' else (X_test, y_test))\n        image_ids[\"index\"] = image_ids[\"index\"].apply(lambda image_id: self._images_folder / f\"image_{image_id:05d}.jpg\")\n        \n        labels = labels - 1\n        \n        self._labels = labels.values\n        self._image_files = image_ids['index'].values\n\n    def __len__(self) -> int:\n        return len(self._image_files)\n\n    def __getitem__(self, idx) -> Tuple[Any, Any]:\n        image_file, label = self._image_files[idx], self._labels[idx]\n        image = PIL.Image.open(image_file).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.target_transform:\n            label = self.target_transform(label)\n\n        return image, label\n\n\n    def extra_repr(self) -> str:\n        return f\"split={self._split}\"\n\n    def _check_integrity(self):\n        if not (self._images_folder.exists() and self._images_folder.is_dir()):\n            return False\n\n        for id in [\"label\", \"setid\"]:\n            filename, md5 = self._file_dict[id]\n            if not check_integrity(str(self._base_folder / filename), md5):\n                return False\n        return True\n\n    def download(self):\n        if self._check_integrity():\n            return\n        download_and_extract_archive(\n            f\"{self._download_url_prefix}{self._file_dict['image'][0]}\",\n            str(self._base_folder),\n            md5=self._file_dict[\"image\"][1],\n        )\n        for id in [\"label\", \"setid\"]:\n            filename, md5 = self._file_dict[id]\n            download_url(self._download_url_prefix + filename, str(self._base_folder), md5=md5)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:12:59.749224Z","iopub.execute_input":"2022-06-27T15:12:59.749892Z","iopub.status.idle":"2022-06-27T15:13:00.167511Z","shell.execute_reply.started":"2022-06-27T15:12:59.749853Z","shell.execute_reply":"2022-06-27T15:13:00.166648Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# preprocssing process","metadata":{}},{"cell_type":"code","source":"# train_data_mean = [0.4231, 0.3578, 0.2785]\n# train_data_std = [0.3086, 0.2553, 0.2731]\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n#     transforms.Resize((230,230)),\n#     transforms.RandomRotation(30,),\n#     transforms.RandomCrop(224),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=train_data_mean, std=train_data_std)\n])\n    \nvalid_transform =  transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n#         transforms.Normalize(mean=train_data_mean, std=train_data_std)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:13:01.803134Z","iopub.execute_input":"2022-06-27T15:13:01.803516Z","iopub.status.idle":"2022-06-27T15:13:01.809684Z","shell.execute_reply.started":"2022-06-27T15:13:01.803469Z","shell.execute_reply":"2022-06-27T15:13:01.808934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# First random split","metadata":{}},{"cell_type":"code","source":"# Download training data from open datasets.\ntraining_data = Flowers102(\n    root=\"data\",\n    split=\"train\",\n    download=True,\n    transform=train_transform\n)\n\ntesting_data = Flowers102(\n    root=\"data\",\n    split=\"test\",\n    download=True,\n    transform=valid_transform\n)\n\nvalid_data = Flowers102(\n    root=\"data\",\n    split=\"val\",\n    download=True,\n    transform=valid_transform\n)\n\n\nimage_datasets = {'train':training_data, 'valid':valid_data, 'test':testing_data}\ndataset_sizes = {i: len(image_datasets[i]) for i in ['train', 'valid','test']}\ndataloaders = {i: DataLoader(image_datasets[i], batch_size=64, shuffle=True) for i in ['train', 'valid','test']}","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:13:02.952093Z","iopub.execute_input":"2022-06-27T15:13:02.952679Z","iopub.status.idle":"2022-06-27T15:13:30.818969Z","shell.execute_reply.started":"2022-06-27T15:13:02.952642Z","shell.execute_reply":"2022-06-27T15:13:30.818049Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# batch_size = 64\n\n# # Create data loaders.\n# train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n# # test_dataloader = DataLoader(test_data, batch_size=batch_size)\n# mean = torch.zeros(3)\n# std = torch.zeros(3)\n# print(len(training_data))\n# for X, y in tqdm(train_dataloader):\n# #     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n# #     print(f\"Shape of y: {y.shape} {y.dtype}\")\n    \n# #     print((torch.mean(X, dim = [0,2,3])))\n#     mean += torch.mean(X, dim = [0,2,3])\n#     std += torch.std(X, dim = [0,2,3])\n# #     print(a)\n# #     print(a)\n# #     break\n\n# print(mean/64)\n# print(std/64)\n    \n# dataloaders = {x: DataLoader(image_datasets[x], batch_size=64,\n#                                              shuffle=True, num_workers=0) for x in ['train', 'valid','test']}","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:13:34.305873Z","iopub.execute_input":"2022-06-27T15:13:34.306688Z","iopub.status.idle":"2022-06-27T15:13:34.316353Z","shell.execute_reply.started":"2022-06-27T15:13:34.306613Z","shell.execute_reply":"2022-06-27T15:13:34.315340Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train(model, criterion, optimizer, num_epochs, plot=True):\n    epoch_train_loss = []\n    epoch_train_acc = []\n    epoch_valid_loss = []\n    epoch_valid_acc = []\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n \n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()\n                append_to_loss = epoch_train_loss\n                append_to_acc = epoch_train_acc\n            else:\n                model.eval()\n                append_to_loss = epoch_valid_loss\n                append_to_acc = epoch_valid_acc\n\n            e_loss = 0\n            e_correct = 0\n\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                e_loss += loss.item() * inputs.size(0)\n                e_correct += torch.sum(preds == labels.data)\n\n            epoch_loss = e_loss / dataset_sizes[phase]\n            epoch_acc = (e_correct.double() / dataset_sizes[phase]).item()\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            \n            append_to_loss.append(epoch_loss)\n            append_to_acc.append(epoch_acc)\n            \n    if plot:\n        # Ploting graphs\n        plt.plot(range(len(epoch_train_loss)), epoch_train_loss,\n                 label='Training')\n        plt.plot(range(len(epoch_valid_loss)), epoch_valid_loss,\n                 label='Validation')\n        plt.ylabel('Cross Entropy error')\n        plt.xlabel('Epoch')\n        plt.legend(loc='upper right')\n        plt.show()\n\n        plt.plot(range(len(epoch_train_acc)), epoch_train_acc,\n                 label='Training')\n        plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc,\n                 label='Validation')\n        plt.ylabel('Accuracy')\n        plt.xlabel('Epochs')\n        plt.legend(loc='lower right')\n        plt.show()\n    \n    return epoch_acc, model","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:13:35.263092Z","iopub.execute_input":"2022-06-27T15:13:35.263653Z","iopub.status.idle":"2022-06-27T15:13:35.278103Z","shell.execute_reply.started":"2022-06-27T15:13:35.263605Z","shell.execute_reply":"2022-06-27T15:13:35.277239Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def test(model):\n    model.eval()\n    res = 0\n    for inputs, labels in tqdm(dataloaders['test']):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            res += torch.sum(preds.double() == labels.data)\n            \n    print(f\"Test set accuracy: {res.item()}/{dataset_sizes['test']} -> {(res / dataset_sizes['test']).item()}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:13:36.007201Z","iopub.execute_input":"2022-06-27T15:13:36.007771Z","iopub.status.idle":"2022-06-27T15:13:36.015787Z","shell.execute_reply.started":"2022-06-27T15:13:36.007731Z","shell.execute_reply":"2022-06-27T15:13:36.014406Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Hyper-parameter optimization on resnet model by simple grid search","metadata":{}},{"cell_type":"code","source":"import itertools\n\nlr = [0.05, 0.1, 0.15]\nmom = [0.3, 0.9, 1]\nne = [3, 5, 10]\na = [lr,mom,ne]\nbest_acc = 0\nbest_hp = []\nfor (lr, momentum, e) in itertools.product(*a):\n    model_resnet = models.resnet152(pretrained=True)\n    resnet_fc_features = model_resnet.fc.in_features\n    fc_resnet = nn.Sequential(\n                nn.Linear(resnet_fc_features, 500),\n                nn.ReLU(inplace=True),\n                nn.Linear(500, 102)\n            )\n    \n    model_resnet.fc = fc_resnet\n    model_resnet = model_resnet.to(device)\n    optimizer = optim.SGD(model_resnet.parameters(), lr=lr, momentum=momentum)\n    criterion = nn.CrossEntropyLoss()\n    acc, model_resnet = train(model_resnet, criterion, optimizer, num_epochs=e, plot=False)\n    \n    if acc > best_acc:\n        best_acc = acc\n        best_hp = [lr,momentum, e]\n\nprint(f'best_acc: {best_acc}, best_hp: {best_hp}')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T12:27:00.555879Z","iopub.execute_input":"2022-06-25T12:27:00.556888Z","iopub.status.idle":"2022-06-25T12:27:00.563539Z","shell.execute_reply.started":"2022-06-25T12:27:00.556852Z","shell.execute_reply":"2022-06-25T12:27:00.562808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First model - resnet152","metadata":{}},{"cell_type":"code","source":"# replace last layer with new hidden layer & adjusted output layer\n\nmodel_resnet = models.resnet152(pretrained=True)\nresnet_fc_features = model_resnet.fc.in_features\n\nfc_resnet = nn.Sequential(\n            nn.Linear(resnet_fc_features, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 102)\n        )\n\nmodel_resnet.fc = fc_resnet\n# model_resnet","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:13:58.797542Z","iopub.execute_input":"2022-06-27T15:13:58.798201Z","iopub.status.idle":"2022-06-27T15:14:12.099553Z","shell.execute_reply.started":"2022-06-27T15:13:58.798165Z","shell.execute_reply":"2022-06-27T15:14:12.098749Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## train and evaluate resnet model on first split","metadata":{}},{"cell_type":"code","source":"model_resnet = model_resnet.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model_resnet.parameters(), lr=0.1, momentum=0.3)\nlast_ac, model_resnet = train(model_resnet, criterion, optimizer, num_epochs=5)\n\ntest(model_resnet)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:14:14.424875Z","iopub.execute_input":"2022-06-27T15:14:14.425860Z","iopub.status.idle":"2022-06-27T15:23:24.803194Z","shell.execute_reply.started":"2022-06-27T15:14:14.425822Z","shell.execute_reply":"2022-06-27T15:23:24.802350Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Second model - vgg19_bn","metadata":{}},{"cell_type":"code","source":"# replace last layer with new hidden layer & adjusted output layer\n\nmodel_vgg19 = models.vgg19_bn(pretrained=True)\nvgg_clf_features = model_vgg19.classifier[0].in_features\n\nclf_vgg = nn.Sequential(\n            nn.Linear(vgg_clf_features, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 102)\n        )\n\nmodel_vgg19.classifier = clf_vgg\n# model_vgg19","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:30:18.753176Z","iopub.execute_input":"2022-06-27T15:30:18.753612Z","iopub.status.idle":"2022-06-27T15:30:47.145525Z","shell.execute_reply.started":"2022-06-27T15:30:18.753578Z","shell.execute_reply":"2022-06-27T15:30:47.144656Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## train and evaluate vgg19 model on first split","metadata":{}},{"cell_type":"code","source":"model_vgg19 = model_vgg19.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model_vgg19.parameters(), lr=0.1, momentum=0.3)\nacc, model_vgg19 = train(model_vgg19, criterion, optimizer_ft, num_epochs=5)\n\ntest(model_vgg19)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:30:47.147437Z","iopub.execute_input":"2022-06-27T15:30:47.147839Z","iopub.status.idle":"2022-06-27T15:39:02.933625Z","shell.execute_reply.started":"2022-06-27T15:30:47.147803Z","shell.execute_reply":"2022-06-27T15:39:02.932824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Second random split","metadata":{}},{"cell_type":"code","source":"# Download training data from open datasets.\ntraining_data = Flowers102(\n    root=\"data\",\n    split=\"train\",\n    download=True,\n    transform=train_transform,\n    random_s=456\n)\n\ntesting_data = Flowers102(\n    root=\"data\",\n    split=\"test\",\n    download=True,\n    transform=valid_transform,\n    random_s=456\n)\n\nvalid_data = Flowers102(\n    root=\"data\",\n    split=\"val\",\n    download=True,\n    transform=valid_transform,\n    random_s=456\n)\n\nimage_datasets = {'train':training_data, 'valid':valid_data, 'test':testing_data}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid','test']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=0)\n               for x in ['train', 'valid','test']}","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:57:43.150380Z","iopub.execute_input":"2022-06-27T15:57:43.150750Z","iopub.status.idle":"2022-06-27T15:57:43.864081Z","shell.execute_reply.started":"2022-06-27T15:57:43.150720Z","shell.execute_reply":"2022-06-27T15:57:43.863290Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## restarting models","metadata":{}},{"cell_type":"code","source":"model_resnet = models.resnet152(pretrained=True)\nresnet_fc_features = model_resnet.fc.in_features\n\nfc_resnet = nn.Sequential(\n            nn.Linear(resnet_fc_features, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 102)\n        )\n\nmodel_resnet.fc = fc_resnet\n# model_resnet\n\nmodel_vgg19 = models.vgg19_bn(pretrained=True)\nvgg_clf_features = model_vgg19.classifier[0].in_features\n\nclf_vgg = nn.Sequential(\n            nn.Linear(vgg_clf_features, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 102)\n        )\n\nmodel_vgg19.classifier = clf_vgg\n# model_vgg19","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:57:44.762455Z","iopub.execute_input":"2022-06-27T15:57:44.763435Z","iopub.status.idle":"2022-06-27T15:57:48.036896Z","shell.execute_reply.started":"2022-06-27T15:57:44.763392Z","shell.execute_reply":"2022-06-27T15:57:48.036026Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## train and evaluate resnet model on second split","metadata":{}},{"cell_type":"code","source":"model_resnet = model_resnet.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model_resnet.parameters(), lr=0.1, momentum=0.3)\nacc, model_resnet = train(model_resnet, criterion, optimizer_ft, num_epochs=5)\n\ntest(model_resnet)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:57:51.009991Z","iopub.execute_input":"2022-06-27T15:57:51.010742Z","iopub.status.idle":"2022-06-27T16:06:42.895724Z","shell.execute_reply.started":"2022-06-27T15:57:51.010704Z","shell.execute_reply":"2022-06-27T16:06:42.894747Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## train and evaluate vgg19 model on second split","metadata":{}},{"cell_type":"code","source":"model_vgg19 = model_vgg19.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model_vgg19.parameters(), lr=0.1, momentum=0.3)\nacc, model_vgg19 = train(model_vgg19, criterion, optimizer_ft, num_epochs=5)\n\ntest(model_vgg19)","metadata":{"execution":{"iopub.status.idle":"2022-06-27T15:56:13.949345Z","shell.execute_reply.started":"2022-06-27T15:47:59.728215Z","shell.execute_reply":"2022-06-27T15:56:13.948510Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# trying bigger models","metadata":{}},{"cell_type":"code","source":"# Download training data from open datasets.\ntraining_data = Flowers102(\n    root=\"data\",\n    split=\"train\",\n    download=True,\n    transform=train_transform,\n)\n\ntesting_data = Flowers102(\n    root=\"data\",\n    split=\"test\",\n    download=True,\n    transform=valid_transform,\n)\n\nvalid_data = Flowers102(\n    root=\"data\",\n    split=\"val\",\n    download=True,\n    transform=valid_transform,\n)\n\nimage_datasets = {'train':training_data, 'valid':valid_data, 'test':testing_data}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid','test']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=0)\n               for x in ['train', 'valid','test']}","metadata":{"execution":{"iopub.status.busy":"2022-06-27T16:18:15.202016Z","iopub.execute_input":"2022-06-27T16:18:15.202802Z","iopub.status.idle":"2022-06-27T16:18:15.796766Z","shell.execute_reply.started":"2022-06-27T16:18:15.202766Z","shell.execute_reply":"2022-06-27T16:18:15.795874Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# CNN with 2 hidden layers","metadata":{}},{"cell_type":"code","source":"model_resnet = models.resnet152(pretrained=True)\nresnet_fc_features = model_resnet.fc.in_features\n\nfc_resnet = nn.Sequential(\n            nn.Linear(resnet_fc_features, 1000),\n            nn.ReLU(inplace=True),\n            nn.Linear(1000, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 102)\n        )\n\nmodel_resnet.fc = fc_resnet\n# model_resnet\n\nmodel_vgg19 = models.vgg19_bn(pretrained=True)\nvgg_clf_features = model_vgg19.classifier[0].in_features\n\nclf_vgg = nn.Sequential(\n            nn.Linear(vgg_clf_features, 1000),\n            nn.ReLU(inplace=True),\n            nn.Linear(1000, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 102)\n        )\n\nmodel_vgg19.classifier = clf_vgg\n# model_vgg19","metadata":{"execution":{"iopub.status.busy":"2022-06-27T16:18:16.376461Z","iopub.execute_input":"2022-06-27T16:18:16.376800Z","iopub.status.idle":"2022-06-27T16:18:19.693271Z","shell.execute_reply.started":"2022-06-27T16:18:16.376772Z","shell.execute_reply":"2022-06-27T16:18:19.692432Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## train and evaluate resnet model","metadata":{}},{"cell_type":"code","source":"model_resnet = model_resnet.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model_resnet.parameters(), lr=0.1, momentum=0.3)\nacc, model_resnet = train(model_resnet, criterion, optimizer_ft, num_epochs=10)\n\ntest(model_resnet)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T16:18:20.408492Z","iopub.execute_input":"2022-06-27T16:18:20.409084Z","iopub.status.idle":"2022-06-27T16:35:45.668073Z","shell.execute_reply.started":"2022-06-27T16:18:20.409048Z","shell.execute_reply":"2022-06-27T16:35:45.667183Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## train and evaluate vgg19 model","metadata":{}},{"cell_type":"code","source":"model_vgg19 = model_vgg19.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model_vgg19.parameters(), lr=0.1, momentum=0.3)\nacc, model_vgg19 = train(model_vgg19, criterion, optimizer_ft, num_epochs=10)\n\ntest(model_vgg19)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T16:35:45.669767Z","iopub.execute_input":"2022-06-27T16:35:45.671382Z","iopub.status.idle":"2022-06-27T16:51:49.305311Z","shell.execute_reply.started":"2022-06-27T16:35:45.671344Z","shell.execute_reply":"2022-06-27T16:51:49.304448Z"},"trusted":true},"execution_count":25,"outputs":[]}]}